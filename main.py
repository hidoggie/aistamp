# main.py (ì´ë¯¸ì§€ ë²¡í„° ê²€ìƒ‰ ìµœì¢… ë²„ì „)

import os, re, io, base64
from pathlib import Path
from contextlib import asynccontextmanager
from fastapi import FastAPI, Body, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import numpy as np
import google.generativeai as genai

# --- 1. ì„¤ì • ---
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
GOOGLE_CREDENTIALS_PATH = "/etc/secrets/google-credentials.json"

# âœ¨ 1. ì„ë² ë”©(ì§€ë¬¸ ì¶”ì¶œ)ê³¼ ì‘ë‹µ ìƒì„± ëª¨ë‘ ë™ì¼í•œ ìµœì‹  ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
MODEL_NAME = "gemini-1.5-pro-flash"

# --- 2. ì „ì—­ ë³€ìˆ˜ ---
app: FastAPI
MODEL: genai.GenerativeModel = None # ëª¨ë¸ ê°ì²´
REFERENCE_VECTORS = [] # { 'id': 'a_sculpture', 'vector': [0.1, 0.2, ...] }
OBJECT_TO_PLANET_MAP = {
    "stamp_1": "earth",   
    "stamp_2": "mars",    
    "stamp_3": "jupiter",
    "stamp_4": "saturn",    
    "stamp_5": "neptune",
}
INITIALIZATION_ERROR = None

# --- 3. Lifespan - ì´ë¯¸ì§€ ì§€ë¬¸(ë²¡í„°) ìƒì„± ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global MODEL, REFERENCE_VECTORS, INITIALIZATION_ERROR
    print("âœ¨ AI ë¹„ì „ ì„œë²„ ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    try:
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = GOOGLE_CREDENTIALS_PATH
        genai.configure(api_key=GEMINI_API_KEY)
        
        # âœ¨ 2. ëª¨ë¸ì„ í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        MODEL = genai.GenerativeModel(MODEL_NAME)
        
        reference_dir = Path(__file__).resolve().parent / "reference_images"
        print("ğŸ¤– ì°¸ì¡° ì´ë¯¸ì§€ë“¤ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        
        for item_dir in reference_dir.iterdir():
            if item_dir.is_dir():
                item_name = item_dir.name
                for image_path in item_dir.glob("*.png"): # .png, .jpg ë“± í™•ì¥ì ì§€ì›
                    print(f"  - {item_name} / {image_path.name} ì§€ë¬¸ ì¶”ì¶œ ì¤‘...")
                    img = Image.open(image_path)
                    # âœ¨ 3. AIì—ê²Œ ì´ë¯¸ì§€ 1ì¥ì„ ë³´ë‚´ 'ì´ë¯¸ì§€ ë²¡í„°'ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
                    response = MODEL.embed_content(
                        content=img, 
                        task_type="RETRIEVAL_DOCUMENT" # "ì´ê²ƒì€ DBìš© ë¬¸ì„œì…ë‹ˆë‹¤"
                    )
                    REFERENCE_VECTORS.append({
                        "id": item_name,
                        "vector": response['embedding']
                    })
        print(f"âœ… {len(REFERENCE_VECTORS)}ê°œì˜ ì°¸ì¡° ë²¡í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        INITIALIZATION_ERROR = f"[{type(e).__name__}] {e}"
        print(f"ğŸ’¥ FATAL: ì•± ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ì›ì¸: {INITIALIZATION_ERROR}")
    yield

app = FastAPI(lifespan=lifespan)
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# --- 4. ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ ---
def find_best_match(query_vector):
    best_match_id = None
    best_score = -1
    
    query_vec = np.array(query_vector)
    
    for item in REFERENCE_VECTORS:
        item_vec = np.array(item["vector"])
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = np.dot(query_vec, item_vec) / (np.linalg.norm(query_vec) * np.linalg.norm(item_vec))
        
        if similarity > best_score:
            best_score = similarity
            best_match_id = item["id"]
            
    print(f"ê°€ì¥ ìœ ì‚¬í•œ ê°ì²´: {best_match_id} (ìœ ì‚¬ë„: {best_score:.2f})")
    # âœ¨ ìœ ì‚¬ë„ ì ìˆ˜ê°€ 0.7 ì´ìƒì¼ ë•Œë§Œ ì¼ì¹˜ë¡œ ì¸ì • (ì´ ê°’ì€ ì¡°ì ˆ ê°€ëŠ¥)
    return best_match_id if best_score > 0.7 else None

# --- 5. API ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/api/recognize-stamp-object")
async def recognize_stamp_object(payload: dict = Body(...)):
    if INITIALIZATION_ERROR: raise HTTPException(status_code=500, detail=f"{INITIALIZATION_ERROR}")

    user_image_b64 = payload.get("image")
    if not user_image_b64: raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    try:
        user_image_bytes = base64.b64decode(user_image_b64.split(',')[1])
        user_image = Image.open(io.BytesIO(user_image_bytes))

        # âœ¨ 4. ì‚¬ìš©ì ì´ë¯¸ì§€ì˜ 'ì´ë¯¸ì§€ ë²¡í„°' ì¶”ì¶œ
        print("ğŸ¤– ì‚¬ìš©ì ì´ë¯¸ì§€ì˜ ë²¡í„° ì¶”ì¶œ ìš”ì²­...")
        response = MODEL.embed_content(
            content=user_image, 
            task_type="RETRIEVAL_QUERY" # "ì´ê²ƒì€ ê²€ìƒ‰ìš© ì§ˆë¬¸ì…ë‹ˆë‹¤"
        )
        query_vector = response['embedding']
        
        # 5. ì €ì¥ëœ ì°¸ì¡° ë²¡í„°ë“¤ê³¼ ê³ ì† ë¹„êµ
        matched_object_name = find_best_match(query_vector)
        
        if matched_object_name:
            planet_id = OBJECT_TO_PLANET_MAP.get(matched_object_name)
            if planet_id:
                return {"status": "success", "planet_id": planet_id}
            else:
                return {"status": "no_match", "description": "ë§¤ì¹­ ì˜¤ë¥˜: ê°ì²´ì— ì—°ê²°ëœ í–‰ì„±ì´ ì—†ìŠµë‹ˆë‹¤."}
        else:
            return {"status": "no_match", "description": "ì¼ì¹˜í•˜ëŠ” ì „ì‹œë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
    except Exception as e:
        print(f"ğŸ’¥ ì´ë¯¸ì§€ ì¸ì‹ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))